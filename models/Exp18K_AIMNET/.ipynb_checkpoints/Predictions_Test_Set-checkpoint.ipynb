{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cbe1ab-e3ea-4846-b8fe-504bc9b07250",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f521302-c75b-42d3-8f32-8a88ae9c5790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 17:48:53.481133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-15 17:48:54.004329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abhijeet/anaconda3/envs/dl_nmr2/lib/:/home/abhijeet/.local/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2025-05-15 17:48:54.004399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abhijeet/anaconda3/envs/dl_nmr2/lib/:/home/abhijeet/.local/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2025-05-15 17:48:54.004405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('modules')\n",
    "from nfp.preprocessing import MolPreprocessor, GraphSequence\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "import random\n",
    "import os\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# DATA PREPROCESSING\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "def atomic_number_tokenizer(atom):\n",
    "    return atom.GetAtomicNum()\n",
    "\n",
    "def _compute_stacked_offsets(sizes, repeats):\n",
    "    return np.repeat(np.cumsum(np.hstack([0, sizes[:-1]])), repeats)\n",
    "\n",
    "def ragged_const(inp_arr):\n",
    "    return tf.ragged.constant(np.expand_dims(inp_arr,axis=0), ragged_rank=1)\n",
    "\n",
    "class RBFSequence(GraphSequence):\n",
    "    def process_data(self, batch_data):\n",
    "        \n",
    "        offset = _compute_stacked_offsets(\n",
    "            batch_data['n_pro'], batch_data['n_atom'])\n",
    "\n",
    "        offset = np.where(batch_data['atom_index']>=0, offset, 0)\n",
    "        batch_data['atom_index'] += offset\n",
    "        \n",
    "        features = ['node_attributes', 'node_coordinates', 'edge_indices', 'atom_index', 'n_pro']\n",
    "        for feature in features:\n",
    "            batch_data[feature] = ragged_const(batch_data[feature])\n",
    "\n",
    "        del batch_data['n_atom']\n",
    "        del batch_data['n_bond']\n",
    "        del batch_data['distance']\n",
    "        del batch_data['bond']\n",
    "        del batch_data['node_graph_indices']\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "with open('data/processed_inputs.p', 'rb') as f:\n",
    "    input_data = pickle.load(f)\n",
    "    \n",
    "test = pd.read_pickle('data/test.pkl.gz')\n",
    "y_test = test.Shifts.values\n",
    "\n",
    "batch_size = 64\n",
    "test_sequence = RBFSequence(input_data['inputs_test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efe4cee-1a16-4d83-9f52-94e58e17dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 17:48:55.233279: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-05-15 17:48:55.233303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: drstrange\n",
      "2025-05-15 17:48:55.233308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: drstrange\n",
      "2025-05-15 17:48:55.233407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.161.7\n",
      "2025-05-15 17:48:55.233424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.161.7\n",
      "2025-05-15 17:48:55.233429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.161.7\n",
      "2025-05-15 17:48:55.233604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from kgcnn.layers.casting import ChangeTensorType\n",
    "from kgcnn.layers.conv.painn_conv import PAiNNUpdate, EquivariantInitialize\n",
    "from kgcnn.layers.conv.painn_conv import PAiNNconv\n",
    "from kgcnn.layers.geom import NodeDistanceEuclidean, BesselBasisLayer, EdgeDirectionNormalized, CosCutOffEnvelope, \\\n",
    "    NodePosition, ShiftPeriodicLattice\n",
    "from kgcnn.layers.modules import LazyAdd, OptionalInputEmbedding\n",
    "from kgcnn.layers.mlp import GraphMLP, MLP\n",
    "from modules.pooling import PoolingNodes\n",
    "from kgcnn.layers.norm import GraphLayerNormalization, GraphBatchNormalization\n",
    "from kgcnn.model.utils import update_model_kwargs\n",
    "ks = tf.keras\n",
    "\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c37f1-92c2-4f65-9bca-99ec4b0f4f7e",
   "metadata": {},
   "source": [
    "### Predctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2497d25-39cf-4a5c-a450-0daefbb737f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 29/29 [00:29<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "for x in tqdm(test_sequence):\n",
    "    predictions.extend(model(x).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cda03d3-9122-45af-891e-d5376f023a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Predictions':predictions})\n",
    "df['Predictions'] = df['Predictions'].apply(lambda x: x*50.162365 +101.062775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddc0dc4-d95c-4b5b-8ad6-7797ce28e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17635.000000</td>\n",
       "      <td>17635.000000</td>\n",
       "      <td>17635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.321978</td>\n",
       "      <td>101.315674</td>\n",
       "      <td>0.754140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.981906</td>\n",
       "      <td>50.045883</td>\n",
       "      <td>1.025445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.152149</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.668102</td>\n",
       "      <td>51.549999</td>\n",
       "      <td>0.182996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>123.062713</td>\n",
       "      <td>123.099998</td>\n",
       "      <td>0.430716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134.121184</td>\n",
       "      <td>134.199997</td>\n",
       "      <td>0.946018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>254.947149</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>21.126682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictions        Actual         Error\n",
       "count  17635.000000  17635.000000  17635.000000\n",
       "mean     101.321978    101.315674      0.754140\n",
       "std       49.981906     50.045883      1.025445\n",
       "min       -5.152149     -5.200000      0.000024\n",
       "25%       51.668102     51.549999      0.182996\n",
       "50%      123.062713    123.099998      0.430716\n",
       "75%      134.121184    134.199997      0.946018\n",
       "max      254.947149    248.000000     21.126682"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Actual'] = np.concatenate(y_test)\n",
    "df['Error'] = abs(df['Actual']-df['Predictions'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ad9b3-87e1-4f24-ba17-4ddfeda021c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_nmr2",
   "language": "python",
   "name": "dl_nmr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cbe1ab-e3ea-4846-b8fe-504bc9b07250",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f521302-c75b-42d3-8f32-8a88ae9c5790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 15:12:20.075331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-15 15:12:20.603483: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abhijeet/anaconda3/envs/dl_nmr2/lib/:/home/abhijeet/.local/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2025-05-15 15:12:20.603552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abhijeet/anaconda3/envs/dl_nmr2/lib/:/home/abhijeet/.local/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2025-05-15 15:12:20.603557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('modules')\n",
    "from nfp.preprocessing import MolPreprocessor, GraphSequence\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "import random\n",
    "import os\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# DATA PREPROCESSING\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "def atomic_number_tokenizer(atom):\n",
    "    return atom.GetAtomicNum()\n",
    "\n",
    "def _compute_stacked_offsets(sizes, repeats):\n",
    "    return np.repeat(np.cumsum(np.hstack([0, sizes[:-1]])), repeats)\n",
    "\n",
    "def ragged_const(inp_arr):\n",
    "    return tf.ragged.constant(np.expand_dims(inp_arr,axis=0), ragged_rank=1)\n",
    "\n",
    "class RBFSequence(GraphSequence):\n",
    "    def process_data(self, batch_data):\n",
    "        \n",
    "        offset = _compute_stacked_offsets(\n",
    "            batch_data['n_pro'], batch_data['n_atom'])\n",
    "\n",
    "        offset = np.where(batch_data['atom_index']>=0, offset, 0)\n",
    "        batch_data['atom_index'] += offset\n",
    "        \n",
    "        features = ['node_attributes', 'node_coordinates', 'edge_indices', 'atom_index', 'n_pro']\n",
    "        for feature in features:\n",
    "            batch_data[feature] = ragged_const(batch_data[feature])\n",
    "\n",
    "        del batch_data['n_atom']\n",
    "        del batch_data['n_bond']\n",
    "        del batch_data['distance']\n",
    "        del batch_data['bond']\n",
    "        del batch_data['node_graph_indices']\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "with open('data/processed_inputs.p', 'rb') as f:\n",
    "    input_data = pickle.load(f)\n",
    "    \n",
    "train = pd.read_pickle('data/train.pkl.gz')\n",
    "valid = pd.read_pickle('data/valid.pkl.gz')\n",
    "test = pd.read_pickle('data/test.pkl.gz')\n",
    "\n",
    "y_train = train.Shifts.values\n",
    "y_valid = valid.Shifts.values\n",
    "y_test = test.Shifts.values\n",
    "\n",
    "for i in range(17315):\n",
    "    y_train[i] -= 99.798111\n",
    "    y_train[i] /= 50.484337\n",
    "    \n",
    "for i in range(2200):\n",
    "    y_valid[i] -= 99.798111\n",
    "    y_valid[i] /= 50.484337\n",
    "\n",
    "batch_size = 64\n",
    "train_sequence = RBFSequence(input_data['inputs_train'], y_train, batch_size)\n",
    "valid_sequence = RBFSequence(input_data['inputs_valid'], y_valid, batch_size)\n",
    "test_sequence = RBFSequence(input_data['inputs_test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efe4cee-1a16-4d83-9f52-94e58e17dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kgcnn.model.utils:Updated model kwargs:\n",
      "INFO:kgcnn.model.utils:{'name': 'PAiNN', 'inputs': [{'shape': (None,), 'name': 'node_attributes', 'dtype': 'float32', 'ragged': True}, {'shape': (None, 3), 'name': 'node_coordinates', 'dtype': 'float32', 'ragged': True}, {'shape': (None, 2), 'name': 'edge_indices', 'dtype': 'int64', 'ragged': True}, {'shape': (None,), 'name': 'atom_index', 'dtype': 'int32', 'ragged': True}, {'shape': (None, 1), 'name': 'n_pro', 'dtype': 'int64', 'ragged': True}], 'input_embedding': {'node': {'input_dim': 256, 'output_dim': 256}}, 'equiv_initialize_kwargs': {'dim': 3, 'method': 'eps'}, 'bessel_basis': {'num_radial': 20, 'cutoff': 5.0, 'envelope_exponent': 5}, 'pooling_args': {'pooling_method': 'mean'}, 'conv_args': {'units': 256, 'cutoff': None}, 'update_args': {'units': 256}, 'equiv_normalization': False, 'node_normalization': False, 'depth': 6, 'verbose': 10, 'output_embedding': 'graph', 'output_to_tensor': True, 'output_mlp': {'use_bias': [True, True], 'units': [256, 1], 'activation': ['swish', 'linear']}, 'Training': False}\n",
      "2025-05-15 15:12:24.685011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-05-15 15:12:24.685035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: drstrange\n",
      "2025-05-15 15:12:24.685040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: drstrange\n",
      "2025-05-15 15:12:24.685153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.161.7\n",
      "2025-05-15 15:12:24.685171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.161.7\n",
      "2025-05-15 15:12:24.685175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.161.7\n",
      "2025-05-15 15:12:24.685317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/abhijeet/Documents/CASCADE_SI_Github/models/Exp22K_FF_GPR/modules/kernel.py:11: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._amplitude = self.add_variable(\n",
      "/home/abhijeet/Documents/CASCADE_SI_Github/models/Exp22K_FF_GPR/modules/kernel.py:16: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  self._length_scale = self.add_variable(\n",
      "/home/abhijeet/anaconda3/envs/dl_nmr2/lib/python3.10/site-packages/tensorflow_probability/python/distributions/gaussian_process.py:448: UserWarning: Unable to detect statically whether the number of index_points is 1. As a result, defaulting to treating the marginal GP at `index_points` as a multivariate Gaussian. This makes some methods, like `cdf` unavailable.\n",
      "  warnings.warn(\n",
      "/home/abhijeet/anaconda3/envs/dl_nmr2/lib/python3.10/site-packages/tensorflow_probability/python/distributions/gaussian_process.py:501: FutureWarning: When the `always_yield_multivariate_normal` arg to `GaussianProcess.__init__` is ignored, after 2023-02-15, `get_marginal_distribution` will always return a Normal distribution with vector event shape. This is the current behavior when `always_yield_multivariate_normal=True`. To recover the behavior of `always_yield_multivariate_normal=False` when `index_points` contains a single index point, build a scalar `Normal` distribution as follows: `mvn = get_marginal_distribution(index_points); ``norm = tfd.Normal(mvn.loc[..., 0], scale=mvn.stddev()[..., 0])`. To suppress these warnings, build the `GaussianProcess` with `always_yield_multivariate_normal=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from kgcnn.layers.casting import ChangeTensorType\n",
    "from kgcnn.layers.conv.painn_conv import PAiNNUpdate, EquivariantInitialize\n",
    "from kgcnn.layers.conv.painn_conv import PAiNNconv\n",
    "from kgcnn.layers.geom import NodeDistanceEuclidean, BesselBasisLayer, EdgeDirectionNormalized, CosCutOffEnvelope, \\\n",
    "    NodePosition, ShiftPeriodicLattice\n",
    "from kgcnn.layers.modules import LazyAdd, OptionalInputEmbedding\n",
    "from kgcnn.layers.mlp import GraphMLP, MLP\n",
    "from modules.pooling import PoolingNodes\n",
    "from kgcnn.layers.norm import GraphLayerNormalization, GraphBatchNormalization\n",
    "from kgcnn.model.utils import update_model_kwargs\n",
    "from modules.model import make_model\n",
    "ks = tf.keras\n",
    "\n",
    "model = make_model(Training=False)\n",
    "model.load_weights('best_model_val_mae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c37f1-92c2-4f65-9bca-99ec4b0f4f7e",
   "metadata": {},
   "source": [
    "### Predctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2497d25-39cf-4a5c-a450-0daefbb737f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 35/35 [01:02<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "for x in tqdm(test_sequence):\n",
    "    predictions.extend(model(x).mean().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cda03d3-9122-45af-891e-d5376f023a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Predictions':predictions})\n",
    "df['Predictions'] = df['Predictions'].apply(lambda x: x*50.484337 +99.798111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddc0dc4-d95c-4b5b-8ad6-7797ce28e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21169.000000</td>\n",
       "      <td>21169.000000</td>\n",
       "      <td>21169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.331192</td>\n",
       "      <td>100.329529</td>\n",
       "      <td>0.783050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50.275896</td>\n",
       "      <td>50.346756</td>\n",
       "      <td>1.110941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.224742</td>\n",
       "      <td>-8.770000</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.649486</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>0.181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>121.653217</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>0.433929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134.237641</td>\n",
       "      <td>134.199997</td>\n",
       "      <td>0.965318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.240810</td>\n",
       "      <td>251.300003</td>\n",
       "      <td>26.361715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictions        Actual         Error\n",
       "count  21169.000000  21169.000000  21169.000000\n",
       "mean     100.331192    100.329529      0.783050\n",
       "std       50.275896     50.346756      1.110941\n",
       "min       -5.224742     -8.770000      0.000010\n",
       "25%       50.649486     50.799999      0.181011\n",
       "50%      121.653217    121.500000      0.433929\n",
       "75%      134.237641    134.199997      0.965318\n",
       "max      244.240810    251.300003     26.361715"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Actual'] = np.concatenate(y_test)\n",
    "df['Error'] = abs(df['Actual']-df['Predictions'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108689eb-028d-45d3-b4dc-203c99a53823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_nmr2",
   "language": "python",
   "name": "dl_nmr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
